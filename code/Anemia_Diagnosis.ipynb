{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uUgutK66zlw"
   },
   "source": [
    "# Packages & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6loeS6IQ6ycJ",
    "outputId": "4e770bd0-a4b0-4b74-f509-79ab2e59b58d"
   },
   "outputs": [],
   "source": [
    "# Data Loading & Pre-Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess, sys\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pingouin as pg\n",
    "#!pip install imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import set_config\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier # LightGBM is 6 times faster than XGBoost.\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ML Model Evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_curve, auc, matthews_corrcoef, cohen_kappa_score, log_loss\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Other imports\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('once')\n",
    "warnings.filterwarnings('ignore', category = DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category = FutureWarning)\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "try:\n",
    "    import ydata_profiling\n",
    "except ImportError:\n",
    "    install('ydata_profiling')\n",
    "\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9H8zT8uQKhG"
   },
   "source": [
    "# Project 1: Anemia Prediction\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "Anemia dataset containing attributes Gender, Hemoglobin, MCHC, MCV, MCH and Results. This dataset is used to predict if a patient is likely to suffer from anemia. Machine learning binary classifier algorithm to be used.\n",
    "\n",
    "Gender:\n",
    "- 0 - male\n",
    "- 1 - female\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**Hemoglobin (g/dl)**: Hemoglobin is a protein in your red blood cells that carries oxygen to your body's organs and tissues and transports carbon dioxide from your organs and tissues back to your lungs\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**MCH (pg)**: MCH is short for \"mean corpuscular hemoglobin.\" It's the average amount in each of your red blood cells of a protein called hemoglobin, which carries oxygen around your body.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**MCHC (g/dl)**: MCHC stands for mean corpuscular hemoglobin concentration. It's a measure of the average concentration of hemoglobin inside a single red blood cell.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "**MCV (f/l)**: MCV stands for mean corpuscular volume. An MCV blood test measures the average size of your red blood cells.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Results:\n",
    "- 0- not anemic\n",
    "- 1-anemic\n",
    "\n",
    "Kaggle link: https://www.kaggle.com/datasets/biswaranjanrao/anemia-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334,
     "referenced_widgets": [
      "0385260673ab4cccacf476811aa025db",
      "533f005be92647c4bfec0ae074b3893c",
      "dbe3f514b3a248f4a88c6a52e074c591",
      "39c59d38c96f411abd45b8dafa91e649",
      "9464d9c7cd8645c3bac9b69c0a8cabd5",
      "698b69e7ade946fe9256180cd5ec8748",
      "24e04369764c4b758894bab119a9c45f",
      "789cddba888e42e798c1658d8e4a0f59",
      "8adb0cf3050e4d89abd250df50452063",
      "13e663c6090f433691569b6221036c6d",
      "257f9c25023941bbb1c0b40efcbf3535",
      "dd719ba24172406e9588098582d407da",
      "0f3cb6593c9d427c9d80a58be10a0793",
      "65d8842f46c34e9fbe4f01ae04612e6c",
      "57f3262402dd49aeae748a340d5a45f2",
      "0d10fb586e3c4e73bcf461ac0aa84241",
      "dead88ca51364640afa2c6a8e122328c",
      "c4cc5e8b68f648a8b926506c74113ad9",
      "9cdd51fc6c094d9f81ae6d1835a2381f",
      "c439d93335b54442acc1ac1fa6b5a001",
      "b3abe4893c534352a6eb9186d43dcb55",
      "61290350ff5a45eabb18a6f3afaf4376",
      "13196fc982c44bd3813fcd66b59375da",
      "74032efc0ce545e38394a5fc79b846d4",
      "e71386c749494e85af1c9746b8fe2668",
      "ef7f34a7ce504612a4a7b7e76c034112",
      "41e0bbd249894d3ab858a27a74303247",
      "00864930f3454a13b78caa3677ad3a27",
      "bc8d2567584f4abd85e5004d0be6aac6",
      "2835cc263d6140918922c2d11d282bff",
      "7ecde3751b254e518174395f3426bedf",
      "52a263cd4eac4fafa82178e9ab98d848",
      "3caa876286da4695b9b8e49b1f1216fb",
      "4113b2e3720e44f3b7127fefd923302e",
      "2e7804c6251b4795b7fa64998c28e2bf",
      "d9e8d4fd7060436da8cf32a2f71cf209",
      "e0614a35d6474a8aaa91e2d2210dc648",
      "1dd6cb181a724b7386811fdd94bde728",
      "e88b70075e7847d79780839ed55bde84",
      "b605a76d4bbc4552811d5f206407bd5e",
      "297982b62f6e46ddbd2f9ac08f499eac",
      "1143bb161c5c4dec870974d1703ae369",
      "3c74df8e17bf4b8880d545b5324d93db",
      "2b13c1cca34f40e5823c831a72f2c90d"
     ]
    },
    "id": "a4IuX9J9OJu3",
    "outputId": "cdd2bf1d-69c0-45ed-c150-9164b72f7244"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/anemia.csv')\n",
    "\n",
    "# Generating a report of the data\n",
    "profile = ProfileReport(data, title = \"Anemia Dataset\")\n",
    "\n",
    "# Saving the report to .html for inspection\n",
    "profile.to_file(\"anemia_dataset_characteristics.html\")\n",
    "\n",
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Upon reviewing the report, the following information is derived:**\n",
    "\n",
    "* The dataset comprises 6 columns/features (2 categorical and 4 numeric) with a total of 1421 observations with 0% missing data.\n",
    "\n",
    "* The 'Gender' column is labeleld as categorical in the report, but upon observing it we say it consists of only two unique values (0 - male & 1 - female). Same is applicable for the 'Result' column.\n",
    "\n",
    "* There are 472 duplicate rows, accounting for 33.2% of the entire dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.iloc[[0, 1]])\n",
    "print((data.iloc[0] - data.iloc[1]).abs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzK_WZX9tHUB"
   },
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "_o_MmtDQREtD",
    "outputId": "efe42388-916a-42e0-cb19-52158128dba7"
   },
   "outputs": [],
   "source": [
    "# checking the types of the columns in the dataset\n",
    "print(data.dtypes)\n",
    "\n",
    "# checking for missing data in the columns of the dataset\n",
    "print('\\n', data.isna().sum(), '\\n')\n",
    "\n",
    "# dataset characteristics\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countplot(col, title, xlabel, ylabel, hue = None):\n",
    "\n",
    "    plt.figure()  # Starts a new figure\n",
    "    ax = sns.countplot(x = col, data = data, hue = hue)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.xticks(ticks = [0, 1], labels = ['Male', 'Female'])\n",
    "    plt.ylabel(ylabel)\n",
    "    \n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "    \n",
    "        ax.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                    ha = 'center', va = 'baseline', fontsize = 10, color = 'black', xytext = (0, 2),\n",
    "                    textcoords = 'offset points')\n",
    "\n",
    "# gender distribution\n",
    "countplot('Gender', 'Gender Distribution in the Dataset', 'Gender', '# of Patients')\n",
    "\n",
    "# gender distribution of anemia cases\n",
    "countplot('Gender', 'Gender Distribution in the Dataset', 'Gender', '# of Patients', hue = 'Result')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is slight imbalance in the dataset (740 female cases vs 681 male cases).\n",
    "\n",
    "* **Nearly twice as many females have anemia compared to males.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anemia_cases = data[data['Result'] == 1]\n",
    "\n",
    "female_anemia_cases = anemia_cases[anemia_cases['Gender'] == 1]\n",
    "male_anemia_cases = anemia_cases[anemia_cases['Gender'] == 0]\n",
    "\n",
    "print(\"Female anemia cases as proportion of all anemia cases: \", np.round(len(female_anemia_cases)/len(anemia_cases), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1DdApeHhrarO",
    "outputId": "00ae3b85-b96a-44e9-b6b8-58fd3b355389"
   },
   "outputs": [],
   "source": [
    "# generating KDE plots for the other columns in the dataset\n",
    "columns_to_plot = [col for col in data.columns if col not in ['Gender', 'Result']]\n",
    "\n",
    "def plot_gender_specific(columns, data, gender_col = 'Gender'):\n",
    "    \n",
    "    for col in columns:\n",
    "        plt.figure()\n",
    "\n",
    "        # Check if the column is categorical or numerical\n",
    "        if data[col].dtype == 'object' or data[col].nunique() < 10:\n",
    "            sns.countplot(x = col, data = data, hue = gender_col)\n",
    "            plt.title(f'Distribution of {col} by Gender')\n",
    "            plt.ylabel('# of Cases')\n",
    "        else:\n",
    "            sns.histplot(data = data, x = col, hue = gender_col, kde = True, element = 'step', stat = 'density', common_norm = False)\n",
    "            plt.title(f'Distribution of {col} by Gender')\n",
    "            plt.ylabel('Density')\n",
    "        \n",
    "        plt.xlabel(col)\n",
    "        plt.legend(title = 'Gender', labels = ['Male', 'Female'])\n",
    "        plt.show()\n",
    "\n",
    "plot_gender_specific(columns_to_plot, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix (heatmap)\n",
    "corr_matrix = data.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, vmin=-1, vmax=1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hemoglobin vs. Result (-0.8): There is a strong negative correlation, indicating that as the hemoglobin increases, the 'Result' tends to decrease, meaning that: \"the higher the hemoglobin, the lower the chance of having anemia\".**\n",
    "\n",
    "Gender vs. Result (0.25): There is a weak positive correlation, meaning there is a slight tendency for the 'Result' to increase as 'Gender' increases, though this relationship is not strong. This means that gender has some statistical importance when determining whether a patient has anemia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GEO4Zzotn2U"
   },
   "source": [
    "### Data Limitations\n",
    "\n",
    "* **DUPLICATE ROWS**\n",
    "* no patient's age provided\n",
    "* no information about other potential illnesses of a patient, nor medical history\n",
    "* no data on:\n",
    "  - MPV\n",
    "  - RDWc\n",
    "  - GRA%\n",
    "  - LYM%\n",
    "  - GRA\n",
    "  - MID\n",
    "  - LYM\n",
    "  - thrombocytes\n",
    "  - leukocytes\n",
    "  - erythrocytes\n",
    "  - hematocrits\n",
    "  - platelets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2BpZTuctZCA"
   },
   "source": [
    "## Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pT6S0O4PxXbT",
    "outputId": "9ad1b0f5-85ba-41b0-b17b-08f57e30e9b6"
   },
   "outputs": [],
   "source": [
    "# train features (X) and target (y)\n",
    "X = data.drop('Result', axis = 1)\n",
    "y = data['Result']\n",
    "\n",
    "# Splitting the data into training and testing sets (80% train & 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Fitting a Logistic Regression Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model's performance\n",
    "print(f'Accuracy: {np.round(accuracy_score(y_test, y_pred) * 100, 2)}%')\n",
    "print(f'Precision: {np.round(precision_score(y_test, y_pred) * 100, 2)}%')\n",
    "print(f'Recall: {recall_score(y_test, y_pred)}')\n",
    "print(f'F1 Score: {np.round(f1_score(y_test, y_pred), 2)}\\n')\n",
    "\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "\n",
    "# ROC Curve and AUC value\n",
    "print(\"ROC Curve: \")\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "auc_score = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label = f'ROC curve (area = {auc_score:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.show()\n",
    "\n",
    "print('\\nMatthews Correlation Coefficient:', np.round(matthews_corrcoef(y_test, y_pred),2))\n",
    "\n",
    "print('Cohen\\'s Kappa Score:', np.round(cohen_kappa_score(y_test, y_pred), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_data = data[data['Gender'] == 1]\n",
    "male_data = data[data['Gender'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNnqEqVl0J-k"
   },
   "source": [
    "## Testing on patient data\n",
    "\n",
    "Gender: Female (1)\n",
    "\n",
    "Hemoglobin: 12.4 (g/dl)\n",
    "\n",
    "MCH: 31.8 (pg)\n",
    "\n",
    "MCV: 77 (f/l)\n",
    "\n",
    "MCHC: 41.1 (g/dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yh9H-bk60Xjd",
    "outputId": "4a8ad2f4-0071-4d53-f4c8-92bdbc592a5f"
   },
   "outputs": [],
   "source": [
    "gender = int(input(\"Enter the Gender (0 for Male, 1 for Female): \"))\n",
    "hemoglobin = float(input(\"Enter the Hemoglobin value: \"))\n",
    "mch = float(input(\"Enter the MCH value: \"))\n",
    "mcv = float(input(\"Enter the MCV value: \"))\n",
    "mchc = float(input(\"Enter the MCHC value: \"))\n",
    "\n",
    "new_data = pd.DataFrame({'Gender': [gender], 'Hemoglobin': [hemoglobin], 'MCH': [mch], 'MCHC': [mchc], 'MCV': [mcv]})\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "\n",
    "prediction = model.predict(new_data_scaled)\n",
    "\n",
    "if prediction == 0:\n",
    "  print(\"The patient is predicted to NOT have anemia.\")\n",
    "else:\n",
    "  print(\"Model Outcome: The patient is predicted to have anemia.\")\n",
    "\n",
    "females_with_anemia = female_data[female_data['Result'] == 1]\n",
    "# Create a new DataFrame combining the user's data and the original data\n",
    "combined_data_anemia = pd.concat([females_with_anemia, new_data], ignore_index = True)\n",
    "combined_data_no_anemia = pd.concat([female_data, new_data], ignore_index = True)\n",
    "\n",
    "# Loop through features and create plots\n",
    "for feature in ['Hemoglobin', 'MCH', 'MCV', 'MCHC']:\n",
    "    plt.figure(figsize = (8, 5))\n",
    "\n",
    "    # Plot the histogram with KDE\n",
    "    sns.histplot(combined_data_no_anemia[feature], kde = True)\n",
    "\n",
    "    # Highlight user's data as a dotted vertical line\n",
    "    plt.axvline(new_data[feature].values[0], color = 'red', linestyle = '--', label = 'Patient Data')\n",
    "\n",
    "    plt.xlim(combined_data_no_anemia[feature].min(), combined_data_no_anemia[feature].max())\n",
    "    plt.title(f'Distribution of {feature} for females')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ktlHXS2a-QE"
   },
   "source": [
    "# Project 2: Anemia Type Classification\n",
    "\n",
    "HGB: The amount of hemoglobin in the blood, crucial for oxygen transport.\n",
    "\n",
    "PlT: The number of platelets in the blood, involved in blood clotting.\n",
    "\n",
    "WBC: The count of white blood cells, vital for immune response.\n",
    "\n",
    "RBC: The count of red blood cells, responsible for oxygen transport.\n",
    "\n",
    "MCV (Mean Corpuscular Volume): Average volume of a single red blood cell.\n",
    "\n",
    "MCH (Mean Corpuscular Hemoglobin): Average amount of hemoglobin per red blood cell.\n",
    "\n",
    "MCHC (Mean Corpuscular Hemoglobin Concentration): Average concentration of hemoglobin in red blood cells.\n",
    "\n",
    "PDW: a measurement of the variability in platelet size distribution in the blood\n",
    "\n",
    "PCT: A procalcitonin test can help your health care provider diagnose if you have sepsis from a bacterial infection or if you have a high risk of developing sepsis\n",
    "\n",
    "Diagnosis: Anemia type based on the CBC parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "a280437ad43e40baa4cb4adf7e78b715",
      "71dcfcc6ad814e9dbc6b7aadf2a82b69",
      "ba0ecb2ee3354aa3a2a8020062d011b7",
      "e0fabd3729f04d349d8c29ca1e647ef5",
      "6332529fbd7244008688b33eabf580c1",
      "3e8fbe7f0e494df8a4caed17286d3a63",
      "ccaeb4a5326d437ab152896b26935efb",
      "6ec75dd15c054db79fb356e57587aaec",
      "9440c1a2579349c8b545fe930b10bca3",
      "f41ee5fc20964e1c9331f970791e9284",
      "7258e3480b1e400fa299fb78f6f32792",
      "ebc2724c5e104e7c90c59f432d89eebe",
      "08c7173dfade46db9b3077e21787b6a4",
      "d5c6f22777eb4ab6a48bcbd0f03a37af",
      "233e6b1a98a249f1871a336dbb9d1bfa",
      "85330e014af84182a60d19c2c33db25d",
      "d3db0534bfb248bfbd40ae886a233413",
      "0dd62fc411c04fe4a39a2dc7a4e38bcf",
      "190a198f0d494f7d9c5be664d4c760ed",
      "173d61e7907444bd83ba1554f3995f1d",
      "b3c2933bd9d54661916034dfd8c2a6f9",
      "a59639f7fe844103a7fa254db8339385",
      "6a7d93fe0b564002b5ca07645aa18e6e",
      "e10fd7453ccf4f13a84bdadbc1e53a47",
      "96d4c1974af2449bbe392320ed136b88",
      "a56275fc6260460bb924a3c2fd40f80e",
      "0c78e59886144376956cfac3f22d02bf",
      "7ddf327b191a499da71d026a8f952afb",
      "d2b433c5cbed4357ace8c8a6ec68d408",
      "1efbc931c98d4e2884cc3f50b6341fdb",
      "e972ad247db742f28c3179dc5125402b",
      "d3cee06941ca48e5979c7aa520c4320d",
      "73ec7b30eb8041f38073ccde360ec48d",
      "8f6d4519fcce44169b61b1039bb65451",
      "db76b2394fea42078e252ad046f98e51",
      "ee35f6da46b942cc80fce3a218ed86f8",
      "abb6550c94434d31b5fe8d5f4416e8c6",
      "ed78d98ad63049568bd7c819989c0c1d",
      "50ca2b479313478cb1a8a40b4f79fe7b",
      "15aa682d7a864fe0badb8a2a20a2cc70",
      "3a8d0c91431d4e17aefa15dd746a77cf",
      "b40b80a2abc04910941fd953ff03b7c0",
      "0501eec8e5e7407f8ac56c9ffecbb0c0",
      "c2ed06b98f4241f6b7b2148ce3a46f25"
     ]
    },
    "id": "wwWcHOx1a_ly",
    "outputId": "2a54e2f5-5348-4593-cd60-a2a8758360af"
   },
   "outputs": [],
   "source": [
    "anemia_data = pd.read_csv('../data/diagnosed_cbc_data_v4-original_data.csv')\n",
    "\n",
    "print(anemia_data.shape)\n",
    "\n",
    "print(anemia_data.Diagnosis.value_counts())\n",
    "\n",
    "anemia_data.describe()\n",
    "\n",
    "# Generating a report of the data\n",
    "#anemia_type_dataset_profile = ProfileReport(anemia_data, title = \"Anemia Type Dataset\")\n",
    "\n",
    "# Saving the report to .html for inspection\n",
    "#anemia_type_dataset_profile.to_file(\"anemia_type_dataset_characteristics.html\")\n",
    "\n",
    "# visualize the number of diagnosis in the dataset as a pie chart and give the exact numbers in parenthesis next to the percentages\n",
    "plt.figure(figsize = (10, 6))\n",
    "plt.pie(anemia_data['Diagnosis'].value_counts(), labels = anemia_data['Diagnosis'].value_counts().index, autopct = '%1.1f%%')\n",
    "plt.title('Distribution of Anemia Types')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anemia_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anemia_data.drop(columns = ['LYMp', 'NEUTp'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is heavily imbalanced under the 'Diagnosis' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix (heatmap)\n",
    "corr_matrix = anemia_data.iloc[:,:-1].corr().round(2)\n",
    "\n",
    "plt.figure(figsize = (12, 5))\n",
    "sns.heatmap(corr_matrix, annot = True, center = 0, vmin = -1, vmax = 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation Ranges and Their Interpretation:**\n",
    "\n",
    "***Perfect Positive Correlation (+1):***\n",
    "\n",
    "* This means that two features move together perfectly; if one feature increases, the other feature always increases in a directly proportional way.\n",
    "Example: If A and B have a correlation of +1, then as A increases, B always increases in the exact same manner.\n",
    "\n",
    "***High Positive Correlation (+0.7 to +1):***\n",
    "\n",
    "* Strong relationship where an increase in one feature is highly likely to be accompanied by an increase in the other feature.\n",
    "* Action: Investigate if features are redundant and consider dropping one of the features if they contain similar information.\n",
    "\n",
    "***Moderate Positive Correlation (+0.4 to +0.7):***\n",
    "\n",
    "* There is a clear positive relationship, but it is not perfect. These features may still contain useful independent information.\n",
    "* Action: Generally, no need to drop either feature unless domain knowledge suggests redundancy.\n",
    "\n",
    "***Low Positive Correlation (+0.1 to +0.4):***\n",
    "\n",
    "* Weak positive relationship; the features increase together, but only slightly.\n",
    "* Action: Low concern for multicollinearity. Keep both features unless otherwise indicated.\n",
    "\n",
    "***No Correlation (-0.1 to +0.1):***\n",
    "\n",
    "* No discernible linear relationship between the features.\n",
    "* Action: Both features can coexist without causing issues of multicollinearity.\n",
    "\n",
    "***Low Negative Correlation (-0.1 to -0.4):***\n",
    "\n",
    "* Weak inverse relationship; as one feature increases, the other tends to decrease slightly.\n",
    "* Action: Similar to weak positive correlation, usually not a concern.\n",
    "\n",
    "***Moderate Negative Correlation (-0.4 to -0.7):***\n",
    "\n",
    "* Clear inverse relationship; as one feature increases, the other decreases in a moderate, predictable way.\n",
    "* Action: Consider if the features are providing redundant information in an inverse way.\n",
    "\n",
    "***High Negative Correlation (-0.7 to -1):***\n",
    "\n",
    "* Strong inverse relationship; as one feature increases, the other decreases in a very predictable and proportional way.\n",
    "* Action: Similar to high positive correlation, you may need to drop or combine features to reduce redundancy.\n",
    "\n",
    "***Perfect Negative Correlation (-1):***\n",
    "\n",
    "* This means that two features are perfectly inversely correlated. As one increases, the other decreases in exact proportion.\n",
    "* Example: If A and B have a correlation of -1, then as A increases, B always decreases by the same amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise correlation with the target variable\n",
    "anemia_data_copy = anemia_data.copy()\n",
    "\n",
    "# encoding the target column\n",
    "label_encoder = LabelEncoder()\n",
    "anemia_data_copy['Diagnosis'] = label_encoder.fit_transform(anemia_data_copy['Diagnosis'])\n",
    "\n",
    "# List of all features (excluding 'Diagnosis' and the control variable 'HGB')\n",
    "features = [col for col in anemia_data_copy.columns if col not in ['Diagnosis', 'HGB']]\n",
    "\n",
    "# Perform partial correlation between each feature and 'Diagnosis', controlling for 'HGB'\n",
    "partial_corr_results = {}\n",
    "for feature in features:\n",
    "    result = pg.partial_corr(data=anemia_data_copy, x=feature, y='Diagnosis', covar='HGB')\n",
    "    partial_corr_results[feature] = result['r'].values[0]\n",
    "\n",
    "partial_corr_df = pd.DataFrame(partial_corr_results.items(), columns=['Feature', 'Partial Correlation (r)'])\n",
    "partial_corr_df = round(partial_corr_df.sort_values(by='Partial Correlation (r)', ascending=False), 2)\n",
    "partial_corr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**r (Partial Correlation Coefficient):**\n",
    "\n",
    "This is the main result: the partial correlation coefficient between 'RBC' and 'Diagnosis', while controlling for 'HGB'.\n",
    "\n",
    "Range: The value of r ranges from -1 to 1.\n",
    "\n",
    "* r = 1: Perfect positive correlation (as 'RBC' increases, 'Diagnosis' increases, after controlling for 'HGB').\n",
    "  \n",
    "* r = -1: Perfect negative correlation (as 'RBC' increases, 'Diagnosis' decreases, after controlling for 'HGB').\n",
    "  \n",
    "* r = 0: No linear relationship between 'RBC' and 'Diagnosis', after controlling for 'HGB'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the features (X) and the target variable (y)\n",
    "X = anemia_data.drop(columns = ['Diagnosis'])\n",
    "y = anemia_data['Diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a constant to the features to account for the intercept\n",
    "X_with_constant = pd.concat([pd.DataFrame({'Intercept': 1}, index=X.index), X], axis=1)\n",
    "\n",
    "# Calculating VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['Feature'] = anemia_data.iloc[:, :-1].columns # all columns but the last which is the diagnosis (categorical)\n",
    "vif_data['VIF'] = [np.round(variance_inflation_factor(X_with_constant.values, i), 2) for i in range(1, X_with_constant.shape[1])]\n",
    "\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Variance Inflation Factor (VIF)** measures the severity of multicollinearity in regression analysis. It is a statistical concept that indicates the increase in the variance of a regression coefficient as a result of collinearity.\n",
    "\n",
    "**Interpreting VIF Values:**\n",
    "\n",
    "* VIF = 1: No multicollinearity.\n",
    "\n",
    "* VIF between 1 and 5: Moderate multicollinearity (usually acceptable).\n",
    "\n",
    "* VIF > 5: High multicollinearity (you should consider removing or combining highly correlated variables).\n",
    "\n",
    "* VIF > 10: Indicates severe multicollinearity, which is typically problematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying over-sampling the minority classes (SMOTE)\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Combining the resampled X and y back into a DataFrame\n",
    "anemia_data_resampled = X_resampled.copy()\n",
    "anemia_data_resampled['Diagnosis'] = y_resampled\n",
    "\n",
    "print(anemia_data_resampled.Diagnosis.value_counts())\n",
    "\n",
    "anemia_data_resampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target (y)\n",
    "X = anemia_data_resampled.drop('Diagnosis', axis = 1)\n",
    "y = anemia_data_resampled['Diagnosis']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "# Data Pre-Processing (only done after the data split): Feature scaling (optional but recommended for some algorithms)\n",
    "scaler = RobustScaler()\n",
    "X_train = scaler.fit_transform(X_train) # fit on training data\n",
    "X_test = scaler.transform(X_test) # transform on test data\n",
    "\n",
    "# Encoding the diagnosis label\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerations\n",
    "\n",
    "**Scaler**\n",
    "\n",
    "* Use RobustScaler() if your data has outliers and you want a robust way to scale your features without being skewed by extreme values. RobustScaler() will scale the data using the median and IQR, making it less sensitive to outliers.\n",
    "  \n",
    "* Use MinMaxScaler() if your models benefit from having input features strictly within a defined range (especially neural networks), but be cautious of outliers. MinMaxScaler() will scale the data between 0 and 1.\n",
    "\n",
    "* Use StandardScaler() if you are working with models that assume normally distributed data and your features are relatively normally distributed without extreme outliers. StandardScaler() will center the data around 0 with a standard deviation of 1.\n",
    "\n",
    "**Evaluation Metrics**\n",
    "\n",
    "***micro:***\n",
    "* Aggregates all TP, FP, FN across classes and calculates the metric globally. Treats every sample equally, making it suitable when you care about the overall performance on individual samples.\n",
    "\n",
    "***macro:***\n",
    "* Averages the metric for each class equally, regardless of how many samples are in each class. Useful when you care about all classes equally.\n",
    "\n",
    "***weighted:***\n",
    "* Like macro, but accounts for the number of samples in each class. It's good when you want to consider class imbalance while still evaluating each class individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model_pipeline = [\n",
    "    XGBClassifier(),\n",
    "    SVC(),\n",
    "    KNeighborsClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    GaussianNB()\n",
    "]\n",
    "\n",
    "model_list = ['XGBoost', 'SVM', 'KNN', 'Decision Tree', 'Random Forest', 'Naive Bayes']\n",
    "acc_list = [] # to store the Accuracy for each model\n",
    "precision_list = [] # to store the Precission for each model\n",
    "recall_list = [] # to store the Recall for each model\n",
    "f1_list = [] # to store the F1 Score for each model\n",
    "\n",
    "times = [] # to store the computation times for each model\n",
    "auc_list = [] # to store the are under the curve for each model\n",
    "cm_list = [] # to store the confusion matrix for each model\n",
    "\n",
    "cf_reports = []\n",
    "\n",
    "y_test_binarized = label_binarize(y_test, classes = range(len(label_encoder.classes_)))\n",
    "\n",
    "for model in model_pipeline:\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    times.append(round(time.time() - start_time, 4)) # recording the model fitting time\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    acc_list.append(round(accuracy_score(y_test, y_pred), 3))\n",
    "    precision_list.append(round(precision_score(y_test, y_pred, average = 'macro'), 3)) # averages the metric across all classes equally.\n",
    "    recall_list.append(round(recall_score(y_test, y_pred, average = 'macro'), 3))\n",
    "    f1_list.append(round(f1_score(y_test, y_pred, average = 'macro'), 3))\n",
    "\n",
    "    # For ROC AUC, use predict_proba if available, otherwise decision_function\n",
    "    try:\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    except AttributeError:\n",
    "        y_proba = model.decision_function(X_test)\n",
    "\n",
    "    # Compute AUC score for multiclass\n",
    "    auc_list.append(round(roc_auc_score(y_test_binarized, y_proba, average = 'macro', multi_class = 'ovr'), 3))\n",
    "    #clf = LogisticRegression(solver=\"liblinear\").fit(X, y)\n",
    "    #roc_auc_score(y, clf.predict_proba(X), multi_class='ovr')\n",
    "\n",
    "    cm_list.append(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    report_dict = classification_report(y_test, y_pred, target_names = label_encoder.classes_, output_dict = True)\n",
    "    \n",
    "    report_df = pd.DataFrame(report_dict).transpose() # converting the dictionary to a DataFrame\n",
    "    report_df[['precision', 'recall', 'f1-score']] = report_df[['precision', 'recall', 'f1-score']].round(3) # rounding to 3 decimal places\n",
    "    report_df['Model'] = model_list[model_pipeline.index(model)]\n",
    "    report_df['Class'] = report_df.index\n",
    "    cf_reports.append(report_df)\n",
    "\n",
    "cf_reports_df = pd.concat(cf_reports, ignore_index = True) # Concatenating all classification reports into a single DataFrame\n",
    "\n",
    "cf_reports_df = cf_reports_df[['Model', 'Class', 'precision', 'recall', 'f1-score', 'support']] # columns rearrangement\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    'Model' : model_list,\n",
    "    'Accuracy' : acc_list,\n",
    "    'Precision' : precision_list,\n",
    "    'Recall' : recall_list,\n",
    "    'F1 Score' : f1_list,\n",
    "    'AUC Score' : auc_list,\n",
    "    'Training Time (s)' : times\n",
    "})\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "cf_reports_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (18, 15))\n",
    "\n",
    "# Assuming 'label_encoder' is the same one used for encoding the labels\n",
    "decoded_labels = label_encoder.inverse_transform([i for i in range(len(label_encoder.classes_))])\n",
    "\n",
    "for i in range(len(cm_list)):\n",
    "    cm = cm_list[i]\n",
    "    model = model_list[i]\n",
    "    \n",
    "    sub = fig.add_subplot(2, 3, i + 1).set_title(model)\n",
    "    \n",
    "    cm_plot = sns.heatmap(cm, annot = True, cmap = 'Blues_r', xticklabels = decoded_labels, yticklabels = decoded_labels)\n",
    "    cm_plot.set_xlabel('Predicted Values')\n",
    "    cm_plot.set_ylabel('Actual Values')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient Data\n",
    "\n",
    "Enter the WBC value: 6.5\n",
    "\n",
    "Enter the LYMp value: 20.4\n",
    "\n",
    "Enter the NEUTp value: 77\n",
    "\n",
    "Enter the LYMn value: 1.33\n",
    "\n",
    "Enter the NEUTn value: 5.14\n",
    "\n",
    "Enter the RBC value: 3.89\n",
    "\n",
    "Enter the HGB value: 12.4\n",
    "\n",
    "Enter the HCT value: 30\n",
    "\n",
    "Enter the MCV value: 77\n",
    "\n",
    "Enter the MCH value: 31.8\n",
    "\n",
    "Enter the MCHC value: 41.1\n",
    "\n",
    "Enter the PLT value: 213\n",
    "\n",
    "Enter the PDW value: 13\n",
    "\n",
    "Enter the PCT value: 0.32\n",
    "\n",
    "https://ramuslab.com/%D1%85%D0%B5%D0%BC%D0%B0%D1%82%D0%BE%D0%BA%D1%80%D0%B8%D1%82-hct/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing an empty dictionary to hold the patient data\n",
    "patient_data = {}\n",
    "\n",
    "# for each column in the dataset, we prompt the user to enter an input\n",
    "for col in anemia_data.columns:\n",
    "    if col != 'Diagnosis':\n",
    "        user_input = float(input(f\"Enter the {col} value: \"))\n",
    "        patient_data[col] = user_input\n",
    "\n",
    "# converting the dictionary into a dataframe with one row\n",
    "patient_data = pd.DataFrame([patient_data])\n",
    "patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_data.to_excel('patient_data_october.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the patient data\n",
    "patient_data_scaled = scaler.transform(patient_data)\n",
    "\n",
    "# List to store the results (Model name and corresponding prediction)\n",
    "predicted_diagnosis = []\n",
    "\n",
    "for i, model in enumerate(model_pipeline):\n",
    "    patient_pred = model.predict(patient_data_scaled)\n",
    "    patient_pred = label_encoder.inverse_transform(patient_pred) # decoding the prediction on the patient data\n",
    "    predicted_diagnosis.append({'Model': model_list[i], 'Prediction': patient_pred[0]})\n",
    " \n",
    "result_df = pd.DataFrame(predicted_diagnosis) # converting the list of dictionaries to a DataFrame\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
